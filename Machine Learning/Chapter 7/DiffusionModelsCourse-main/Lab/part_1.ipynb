{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training score-based diffusion model from first principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will walk step-by-step over the key steps of training a diffusion model.\n",
    "The use-case here is to learn a diffusion model to generate a cloud of points that writes the word *\"AI\"*.\n",
    "\n",
    "\n",
    "The dataset is available in the folder ``assets/2D_data/``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "cloud_points = torch.load(\"assets/2D_data/cloud_points.pt\")\n",
    "\n",
    "# get the number of samples\n",
    "cloud_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cloud of points\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(\n",
    "    cloud_points[:, 0], cloud_points[:, 1], alpha=0.5\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "For the analogy, in the case of a dataset of images, each point in the cloud of points will represent an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn the dataset into a Gaussian distribution.\n",
    "This can be described using a Markov process\n",
    "$$\n",
    "x_t  = \\sqrt{\\alpha}_t x_{t-1} + \\sqrt{1 - \\alpha_t} \\varepsilon_t \\\\\n",
    "x_0  \\sim p_{data}, \\quad\n",
    "(\\varepsilon_t)_t \\overset{iid}{\\sim} \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "We needn't to follow recurrently the chain $x_0 \\rightarrow x_1 \\rightarrow x_2 \\rightarrow \\dots \\rightarrow x_t$ to get a sample $x_t$, we can jump directly from $x_0 \\rightarrow x_t$\n",
    "\n",
    "$$\n",
    "x_t  = \\sqrt{\\bar{\\alpha}}_t x_0 + \\sqrt{1 - \\bar{\\alpha_t}} \\epsilon_t, \\quad\n",
    "\\bar{\\alpha}_t = \\textstyle \\prod_k \\alpha_k\n",
    "$$\n",
    "\n",
    "**Question**: Can you show it?\n",
    "\n",
    "\n",
    "The sequence $\\bar{\\alpha}_t$ is the so called **noise scheduler**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import linear scheduler an see what it does.\n",
    "It is available in the provided code in under ``py_code/diffusion.py``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the scheduler\n",
    "from assets.py_code.diffusion import linear_schedule\n",
    "\n",
    "n_diffusion_steps = 1000\n",
    "alphas_cumprod = linear_schedule(n_diffusion_steps)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(alphas_cumprod.sqrt(), label=\"x_0 coef\")\n",
    "ax.plot((1 - alphas_cumprod).sqrt(), label=\"noise coef\")\n",
    "\n",
    "ax.set_xlabel(\"diffusion step t\")\n",
    "ax.set_aspect(250)\n",
    "ax.legend(loc=\"lower center\", ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Can you comment this figure? what happens to the $x_0$ and the noise as the time evolve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_time = [0, 50, 100, 200, 999]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(selected_time),)\n",
    "\n",
    "for ax, t in zip(axes, selected_time):\n",
    "    acp_t = alphas_cumprod[t]\n",
    "    noise = torch.randn_like(cloud_points)\n",
    "\n",
    "    x_t = acp_t.sqrt() * cloud_points + (1 - acp_t).sqrt() * noise\n",
    "\n",
    "    ax.scatter(x_t[:, 0], x_t[:, 1], s=1, alpha=0.2)\n",
    "    ax.set_title(f\"{t = }\")\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning a Denoising Diffusion Probabilistic Model (DDPM) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to learn a noise predictor\n",
    "$$\n",
    "\\epsilon_{\\theta}(x_t, t)\n",
    "$$\n",
    "given an $x_t$, it predict the noise that was added to $x_0$.\n",
    "\n",
    "We model the noise predictor as a Neural Network.\n",
    "\n",
    "Notice that we have to learn a NN that depends on time.\n",
    "Therefore, we need a way to embed the information of time in it.\n",
    "We achieve that using positional encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn a simple MLP to predict the added noise.\n",
    "For positional encoding, we will learn a table of vector, where each vector is an embedding of a time step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement this architecture\n",
    "\n",
    "<img src=\"./illustrations/architecutre.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class EpsilonNet(nn.Module):\n",
    "\n",
    "    def __init__(self, d_encoding=20, n_blocks=5, n_diffusion_steps=50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_encoding = d_encoding\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_diffusion_steps = n_diffusion_steps\n",
    "\n",
    "        self.position_encoder = nn.Embedding(\n",
    "            embedding_dim=self.d_encoding, num_embeddings=n_diffusion_steps\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(2, self.d_encoding),\n",
    "            nn.BatchNorm1d(self.d_encoding),\n",
    "        )\n",
    "\n",
    "        layers = [BlockMLP(d_encoding, d_encoding) for _ in range(n_blocks)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.d_encoding, 2),\n",
    "            nn.BatchNorm1d(2)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, noisy_points: torch.Tensor, t: int | torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        out = self.encoder(noisy_points) + self.position_encoder(t)\n",
    "        out = self.network(out)\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class BlockMLP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show that training a diffusion models reduces to minimizes the following loss\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\min_\\theta \\ \\mathbb{E}_{x_0, t, \\epsilon} \\| \\epsilon - \\epsilon_{\\theta}(x_t, t) \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model for 1000 epoch using Adam optimizer with learning rate of ``lr=0.01``.\n",
    "\n",
    "**Question**: from the code below, what are the other tweaks used for training the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "data_loader = DataLoader(cloud_points, batch_size=len(cloud_points) // 10, shuffle=True)\n",
    "\n",
    "n_diffusion_steps = 1000\n",
    "n_epochs = 1000\n",
    "lr = 1e-2\n",
    "\n",
    "alphas_cumprod = linear_schedule(n_diffusion_steps)\n",
    "alphas_cumprod = alphas_cumprod.to(device)\n",
    "\n",
    "eps_net = EpsilonNet(d_encoding=20, n_blocks=5, n_diffusion_steps=n_diffusion_steps)\n",
    "eps_net.to(device)\n",
    "eps_net.train()\n",
    "\n",
    "optimizer = Adam(eps_net.parameters(), lr)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=lr / 100)\n",
    "\n",
    "\n",
    "for epoch in (tbar := tqdm(range(n_epochs))):\n",
    "\n",
    "    for batch_points in data_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_points = batch_points.to(device)\n",
    "        timesteps = torch.randint(\n",
    "            size=(len(batch_points),),\n",
    "            low=0,\n",
    "            high=n_diffusion_steps,\n",
    "            device=device\n",
    "        )\n",
    "        noise = torch.randn_like(batch_points, device=device)\n",
    "\n",
    "        # noise the data\n",
    "        acp_t = alphas_cumprod[timesteps][:, None]\n",
    "        x_t = acp_t.sqrt() * batch_points + (1 - acp_t).sqrt() * noise\n",
    "\n",
    "        # predict the added noise\n",
    "        predicted_noise = eps_net(x_t, timesteps)\n",
    "\n",
    "        # backprop the error\n",
    "        loss = torch.norm(predicted_noise - noise) ** 2\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        tbar.set_description(f\"loss per batch = {loss.item():.8f}\")\n",
    "\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that, we trained the model let set it to inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_net.eval()\n",
    "eps_net.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straight forward way to generate new sample is to simulate backward in time the markov chain.\n",
    "\n",
    "This is commonly referred to as *ancestral sampling* [1].\n",
    "\n",
    "\n",
    "<img src=\"./illustrations/sampling_algo.png\" />\n",
    "\n",
    ".. [1] Ho, Jonathan, Ajay Jain, and Pieter Abbeel.\n",
    "    \"Denoising diffusion probabilistic models.\"\n",
    "    Advances in neural information processing systems 33 (2020): 6840-6851."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function to perform ancestral sampling\n",
    "\n",
    "def ancestral_sampling(initial_noise: torch.Tensor):\n",
    "    device = initial_noise.device\n",
    "    x_t = initial_noise\n",
    "\n",
    "    for t in reversed(range(1, n_diffusion_steps)):\n",
    "        t = torch.tensor(t, device=device)\n",
    "        t_prev = t - 1\n",
    "        pred_noise = eps_net(x_t, t)\n",
    "\n",
    "        acp_t, acp_t_prev = alphas_cumprod[t], alphas_cumprod[t_prev]\n",
    "        alpha_t = acp_t / acp_t_prev\n",
    "\n",
    "        sigma_t = torch.sqrt((1 - acp_t_prev) / (1 - acp_t) * (1 - alpha_t))\n",
    "        coef_pred_noise = (1 - alpha_t) / (1 - acp_t).sqrt()\n",
    "\n",
    "        noise = torch.randn_like(x_t, device=device)\n",
    "        x_t = (x_t - coef_pred_noise * pred_noise) / alpha_t.sqrt() + sigma_t * noise\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new samples\n",
    "n_samples = 5_000\n",
    "initial_noise = torch.randn((n_samples, 2), device=device)\n",
    "generated_points = ancestral_sampling(initial_noise)\n",
    "generated_points = generated_points.cpu()\n",
    "\n",
    "# plot generated vs. real\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(12, 6))\n",
    "\n",
    "# Plot ground truth points\n",
    "ax = axes[0]\n",
    "p = cloud_points.cpu()\n",
    "ax.scatter(p[:, 0], p[:, 1], label=\"real\", alpha=0.3, s=5)\n",
    "ax.set_title(\"Ground Truth Points\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_aspect(1)\n",
    "ax.legend()\n",
    "\n",
    "# Plot generated points\n",
    "ax = axes[1]\n",
    "p = generated_points.cpu()\n",
    "ax.scatter(p[:, 0], p[:, 1], label=\"generated\", alpha=0.3, s=5)\n",
    "ax.set_title(\"Generated Points\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_aspect(1)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new samples\n",
    "n_samples = 5_000\n",
    "initial_noise = torch.randn((n_samples, 2), device=device)\n",
    "generated_points = ancestral_sampling(initial_noise)\n",
    "generated_points = generated_points.cpu()\n",
    "\n",
    "# plot generated vs. real\n",
    "# make a second plot of the histogram of the generated points\n",
    "fig, axes = plt.subplots(1, 2, sharey=True, sharex=True)\n",
    "ax = axes[0]\n",
    "for points, label in zip((cloud_points, generated_points), (\"real\", \"generated\")):\n",
    "    p = points.cpu()\n",
    "    ax.scatter(p[:, 0], p[:, 1], label=label, alpha=0.3, s=5)\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_aspect(1)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.hist2d(generated_points[:, 0], generated_points[:, 1], bins=15, cmap=\"Oranges\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_aspect(1)\n",
    "\n",
    "fig.legend(loc=\"upper center\", ncol=2,  bbox_to_anchor=(0.5, 0.8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
